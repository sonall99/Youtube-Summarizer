{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06afb670-00dd-4a22-958b-1a3a3387c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53e245d-d8b7-443b-a775-c05975db7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U youtube-transcript-api google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c2a93a-d4cc-4f05-9bf8-fdfe2bade293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e13a9e-ecb3-4995-b5f5-80f451a47b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff33e7a3-84a4-4838-a2b8-fb257b0ec482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        yt = YouTubeTranscriptApi()\n",
    "        transcripts = yt.list(video_id)\n",
    "\n",
    "        try:\n",
    "            transcript_obj = transcripts.find_transcript(['en-IN'])\n",
    "        except:\n",
    "            print(\"No 'en-IN' transcript found. Falling back to 'hi'.\")\n",
    "            transcript_obj = transcripts.find_transcript(['hi'])\n",
    "\n",
    "        transcript_data = transcript_obj.fetch()\n",
    "        full_text = \" \".join([item.text for item in transcript_data])\n",
    "        return full_text, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa74c40d-8f01-453f-a01a-63569e644ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7475ee-a5eb-4cdb-9d43-91802b7cd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b57506e-337d-4bcb-950a-1daba9e8b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "GOOGLE_API_KEY=AIzaSyA24Z7SDJ5npyCEN7-LFOtFIocpS4V9sy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc5b3c8-c018-4546-8491-d742325a311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API configured successfully!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "print(\"Gemini API configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29777e20-7d1f-44f3-8949-9625b3379b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading summarization model...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the summarization model.\n",
    "print(\"Loading summarization model...\")\n",
    "model = genai.GenerativeModel('models/gemini-2.5-pro')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba3817f-8890-4ac4-a646-591324b5f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_gemini(transcript):\n",
    "    \"\"\"\n",
    "    Sends the transcript to Gemini and asks it to\n",
    "    translate (if needed) and summarize.\n",
    "    \"\"\"\n",
    "    print(\"Sending transcript to Gemini...\")\n",
    "    \n",
    "    # This is the prompt that tells Gemini what to do.\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert YouTube video summarizer.\n",
    "    Your task is to provide a concise, easy-to-read summary in English.\n",
    "    \n",
    "    Follow these two steps:\n",
    "    1.  The following text is a video transcript. First, check if it is in Hindi. If it is in Hindi, translate it to English. If it is already in English, you can skip this translation step.\n",
    "    2.  After ensuring the text is in English, provide a high-quality summary of the content. The summary should capture the main points and key takeaways.\n",
    "    \n",
    "    Transcript:\n",
    "    \"{transcript}\"\n",
    "    \n",
    "    English Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1d3a57e-ed54-46fe-8052-d40796ffd58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching transcript for video: 1Jgoaj_Kudc\n",
      "Sending transcript to Gemini...\n",
      "\n",
      "==============================\n",
      "    GEMINI SUMMARY (IN ENGLISH)\n",
      "==============================\n",
      "\n",
      "This video addresses the feeling of being stuck in a cycle of procrastination,\n",
      "lethargy, and self-sabotage. It introduces a concept from the Bhagavad Gita\n",
      "(Chapter 18, Verse 28) to explain this state: **Tamasic action**.  Tamasic\n",
      "action is described not as an evil deed, but as a subtle, destructive state\n",
      "characterized by: *   **Lack of purpose (Ayukta):** Feeling scattered and living\n",
      "without a clear daily rhythm. *   **Impulsiveness (Prakrita):** Letting\n",
      "instincts and boredom dictate your actions (e.g., eating, sleeping) over\n",
      "intelligent choices. *   **Stubbornness (Stabdha):** Knowing you're stuck but\n",
      "making excuses and choosing comfort over correction. *   **Self-deception\n",
      "(Shatha):** Lying to yourself by framing procrastination as \"planning\" or\n",
      "avoidance as \"rest.\" *   **Harmful inaction:** Choosing not to act is still a\n",
      "choice, and when driven by delusion and carelessness, it becomes destructive.\n",
      "The speaker clarifies that **Tamas is different from simple tiredness**. While\n",
      "rest is refreshing, Tamas is a lingering state of numbness that drains you\n",
      "silently.  The video emphasizes that the solution is not motivation or shame,\n",
      "but **honesty and awareness**. The path to overcoming Tamas involves taking\n",
      "small, deliberate steps. Three \"weapons\" are suggested: 1.  Do one thing that\n",
      "scares you. 2.  Set a boundary with your comfort zone. 3.  Be honest with\n",
      "yourself.  Finally, the summary makes a crucial distinction: **The Gita's\n",
      "message is not \"hustle culture.\"** Hustle is often driven by fear and anxiety,\n",
      "demanding constant busyness. The Gita, in contrast, promotes acting with\n",
      "clarity, courage, and awareness. The opposite of Tamas is **Sattva**—a state of\n",
      "calm, noble energy. The goal isn't to do more, but to ask *why* you are doing it\n",
      "and to act with purpose and presence.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SET YOUR VIDEO URL HERE ---\n",
    "# Hindi video (to test translation + summary)\n",
    "video_url = \"https://www.youtube.com/watch?v=1Jgoaj_Kudc\" \n",
    "# English video (to test summary only)\n",
    "# video_url = \"https://www.youtube.com/watch?v=UvYh3hV22jA\" \n",
    "\n",
    "# --- 2. Extract Video ID ---\n",
    "try:\n",
    "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
    "except:\n",
    "    print(\"Invalid YouTube URL. Make sure it's not a 'short' or a 'live' video.\")\n",
    "    video_id = None\n",
    "\n",
    "if video_id:\n",
    "    # --- 3. Get Transcript ---\n",
    "    print(f\"Fetching transcript for video: {video_id}\")\n",
    "    transcript, error = get_transcript(video_id)\n",
    "    \n",
    "    if transcript:\n",
    "        # --- 4. Get Summary with Gemini ---\n",
    "        summary, error = summarize_with_gemini(transcript)\n",
    "        \n",
    "        if summary:\n",
    "            # --- 5. Print the Results ---\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"    GEMINI SUMMARY (IN ENGLISH)\")\n",
    "            print(\"=\"*30 + \"\\n\")\n",
    "            print(textwrap.fill(summary, width=80))\n",
    "        else:\n",
    "            print(f\"Error generating summary: {error}\")\n",
    "    else:\n",
    "        print(f\"Could not fetch transcript. Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07db939e-a9df-45ca-86f0-19e386cd8a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 — ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp — ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation — ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts — ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts — ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental — ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it — ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it — ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it — ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it — ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it — ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it — ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview — ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image — ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-09-2025 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview — ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-computer-use-preview-10-2025 — ['generateContent', 'countTokens']\n",
      "models/embedding-001 — ['embedContent']\n",
      "models/text-embedding-004 — ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 — ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp — ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 — ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa — ['generateAnswer']\n",
      "models/imagen-4.0-generate-preview-06-06 — ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 — ['predict']\n",
      "models/imagen-4.0-generate-001 — ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 — ['predict']\n",
      "models/imagen-4.0-fast-generate-001 — ['predict']\n",
      "models/veo-2.0-generate-001 — ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 — ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 — ['predictLongRunning']\n",
      "models/veo-3.1-generate-preview — ['predictLongRunning']\n",
      "models/veo-3.1-fast-generate-preview — ['predictLongRunning']\n",
      "models/gemini-2.0-flash-live-001 — ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview — ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview — ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-native-audio-latest — ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 — ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name, \"—\", m.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f06183-a97b-43c2-9a5a-a4d6a44ab5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
